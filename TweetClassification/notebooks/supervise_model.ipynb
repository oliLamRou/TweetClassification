{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e0d734d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30cfbf3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4807 entries, 0 to 4806\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   date     4807 non-null   object\n",
      " 1   line     4807 non-null   object\n",
      " 2   tweet    4807 non-null   object\n",
      " 3   stop     4807 non-null   int64 \n",
      " 4   restart  4807 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 187.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Load raw\n",
    "#raw to clean tweet\n",
    "#pre process tweet\n",
    "#one hot encoding stop, slow, restart\n",
    "\n",
    "\n",
    "df = pd.read_csv('../../data/tweets_one_hot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "656c9e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_short_word(tweet):\n",
    "    tweet_ = []\n",
    "    for word in tweet.split():\n",
    "        if len(word) < 4:\n",
    "            continue\n",
    "            \n",
    "        tweet_.append(word)\n",
    "\n",
    "    return \" \".join(tweet_)\n",
    "\n",
    "#Remove english\n",
    "#beaudry station reopened regular service resuming station\n",
    "swe = stopwords.words('english')\n",
    "swe_ = []\n",
    "for word in swe:\n",
    "    if len(word) < 4:\n",
    "        continue\n",
    "    \n",
    "    swe_.append(word)\n",
    "\n",
    "def sw_in(tweet):\n",
    "    for word in tweet.split():\n",
    "        if word in swe_:\n",
    "            return True\n",
    "        \n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "b5360d1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1781"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/tweets_one_hot.csv')\n",
    "tweet = df.tweet\n",
    "\n",
    "#REGEX and Character removal\n",
    "regex = [\n",
    "    (r\"@\\S*\"),\n",
    "    (r\"#\\w+\"),\n",
    "    (r\"http\\S*\"),\n",
    "    (r\"\\b\\d+(\\.\\d+)?K\\b\"),\n",
    "    (r\"\\d{1,2}h\\d{2}\"),\n",
    "    (r\"[\\[\\]()\\/\\\\!?.,:;]\"),\n",
    "    \"BLEUE\",\n",
    "    \"VERTE\",\n",
    "    \"JAUNE\",\n",
    "    \"ORANGE\",\n",
    "    \"show\",\n",
    "    \"more\",\n",
    "    \"this\"\n",
    "]\n",
    "for r in regex:\n",
    "    tweet = tweet.str.replace(r, \"\", regex=True)\n",
    "\n",
    "#Lower case everything\n",
    "tweet = tweet.str.lower()\n",
    "\n",
    "#Remove short word\n",
    "tweet = tweet.apply(remove_short_word)\n",
    "\n",
    "#Remove english\n",
    "tweet = tweet[~tweet.apply(sw_in)]\n",
    "\n",
    "df['tweet_preprocess'] = tweet\n",
    "\n",
    "#remove nan\n",
    "df = df[df.tweet_preprocess.notna()]\n",
    "df.tweet_preprocess.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "7414b887",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../data/tweets_one_hot_textProcess.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5788fb44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44fc7e77",
   "metadata": {},
   "source": [
    "# DEEP LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "915f6531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('prolongé', 0.9820728302001953), ('train', 0.9786366820335388), ('bonaventure', 0.9757501482963562), ('h-bourassa', 0.9742446541786194), ('beaubien', 0.9738559126853943)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Tokenize the tweets\n",
    "tokenized_tweets = [tweet.split() for tweet in df.tweet.values]\n",
    "\n",
    "# Train Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=tokenized_tweets, vector_size=32, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Example usage:\n",
    "word_vectors = word2vec_model.wv\n",
    "similar_words = word_vectors.most_similar('arrêt', topn=5)\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "aae2172f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:\n",
      "['reprise graduelle service ligne', 'reprise graduelle service ligne', 'reprise graduelle service ligne', 'reprise graduelle service ligne', 'reprise graduelle service ligne']\n",
      "\n",
      "Cluster 1:\n",
      "['arrêt ligne entre snowdon st-michel personne autorisée voie reprise prévue vers', \"arrêt ligne entre snowdon st-michel problème d'équipement électrique reprise prévue vers\", \"arrêt ligne entre snowdon st-michel inter services médicaux d'urgence reprise prévue vers\", 'arrêt prolongé ligne entre snowdon st-michel incident durée indéterminée', 'arrêt ligne entre snowdon st-michel incident durée indéterminée']\n",
      "\n",
      "Cluster 2:\n",
      "['service normal métro', 'service normal métro ligne', 'service normal métro ligne', 'service normal métro ligne', 'service normal métro']\n",
      "\n",
      "Cluster 3:\n",
      "['arrêt ligne entre côte-vertu l-groulx dégagement fumée reprise prévue vers', 'arrêt ligne entre snowdon parc dégagement fumée reprise prévue vers', 'arrêt prolongé ligne entre côte-vertu l-groulx dégagement fumée reprise prévue vers', 'arrêt ligne entre berri-uqam h-bourassa dégagement fumée reprise prévue vers', 'arrêt prolongé ligne entre berri-uqam h-bourassa dégagement fumée reprise prévue vers']\n",
      "\n",
      "Cluster 4:\n",
      "['arrêt ligne entre côte-vertu berri-uqam incident reprise prévue vers', 'arrêt ligne entre h-bourassa montncy incident durée indéterminée', 'arrêt ligne entre l-groulx berri-uqam incident reprise prévue vers', 'arrêt prolongé ligne entre l-groulx berri-uqam incident reprise prévue vers', 'arrêt prolongé ligne entre berri-uqam frontenac incident durée indéterminée']\n",
      "\n",
      "Cluster 5:\n",
      "[\"arrêt ligne entre angrignon h-beaugrand inter services médicaux d'urgence reprise prévue vers\", \"arrêt ligne entre l-groulx berri-uqam inter services médicaux d'urgence reprise prévue vers\", \"arrêt prolongé ligne entre l-groulx berri-uqam inter services médicaux d'urgence reprise prévue vers\", \"arrêt prolongé ligne entre l-groulx berri-uqam inter services médicaux d'urgence reprise prévue vers\", \"arrêt ligne entre côte-vertu berri-uqam inter services médicaux d'urgence reprise prévue vers\"]\n",
      "\n",
      "Cluster 6:\n",
      "[\"arrêt ligne entre longueuil berri-uqam problème d'équipement reprise prévue vers\", \"arrêt ligne entre longueuil berri-uqam problème d'équipement reprise prévue vers\", \"arrêt ligne entre longueuil berri-uqam problème d'équipement reprise prévue vers\", \"arrêt ligne entre longueuil berri-uqam problème d'équipement reprise prévue vers\", \"arrêt ligne entre longueuil berri-uqam problème d'équipement reprise prévue vers\"]\n",
      "\n",
      "Cluster 7:\n",
      "['aucun arrêt trains station beaudry', 'aucun arrêt trains station beaudry', 'fermeture station beaudry raison d’une intervention policière proximité station aucun arrêt trains station pour durée indéterminée', 'station beaudry fermée vous pouvez prendre métro stations berri-uqam papineau situées proximité service toujours offert ligne verte mais aucun arrêt trains station beaudry', 'aucun arrêt trains station saint-laurent']\n",
      "\n",
      "Cluster 8:\n",
      "[\"arrêt ligne entre longueuil berri-uqam inter services d'urgence reprise prévue vers\", \"arrêt ligne entre longueuil berri-uqam inter services d'urgence reprise prévue vers\", \"arrêt ligne entre longueuil berri-uqam inter services d'urgence reprise prévue vers\", \"arrêt ligne entre longueuil berri-uqam inter services d'urgence reprise prévue vers\", \"arrêt ligne entre longueuil berri-uqam inter services d'urgence reprise prévue vers\"]\n",
      "\n",
      "Cluster 9:\n",
      "[\"distribution couvre-visage port couvre-visage fortement recommandé distribution aura lieu aujourd'hui stations h-beaugrand radisson langelier viau pie-ix l'église pour voir calendrier distribution\", \"distribution couvre-visage port couvre-visage fortement recommandé dans métro distribution aura lieu aujourd'hui stations saint-michel parc voir calendrier distribution\", \"distribution couvre-visage port couvre-visage fortement recommandé dans métro distribution aura lieu aujourd'hui stations h-bourassa sauvé crémazie laurier mont-royal sherbrooke voir calendrier distribution\", \"distribution couvre-visages distribution aura lieu aujourd'hui stations berri-uqam place-des-arts guy-concordia atwater lionel-groulx consultez calendrier distribution\", \"distribution couvre-visages distribution aura lieu aujourd'hui stations côte-vertu collège snowdon vendôme l-groulx square-victoria place-d'armes champ-de-mars berri-uqam consultez calendrier distribution\"]\n",
      "\n",
      "Cluster 10:\n",
      "['arrêt ligne entre atwater berri-uqam personne blessée malade reprise prévue vers', 'arrêt ligne entre atwater berri-uqam personne blessée malade reprise prévue vers', 'arrêt ligne entre snowdon st-michel personne blessée malade reprise prévue vers', 'arrêt ligne entre snowdon bonaventure personne blessée malade reprise prévue vers', 'arrêt prolongé ligne entre snowdon bonaventure personne blessée malade reprise prévue vers']\n",
      "\n",
      "Cluster 11:\n",
      "['interruption cours pour d’autres options pour déplacements vous pouvez utiliser calculateur d’itinéraires décochant l’option métro', 'vous pouvez utiliser calculateur d’itinéraires décochant l’option «utilisation métro»', 'vous pouvez utiliser calculateur d’itinéraires décochant l’option «utilisation métro»', 'interruption cours pour d’autres options pour déplacements calculateur d’itinéraires décochant option métro', 'pour d’autres options pour déplacements calculateur d’itinéraires décochant option métro']\n",
      "\n",
      "Cluster 12:\n",
      "['interruption cours vous pouvez utiliser lignes hochelaga sherbrooke pour vous déplacer entre stations pie-ix honoré-beaugrand', 'vous pouvez aussi utiliser ligne 51-édouard-montpetit ligne orange pour déplacements entre stations snowdon jean-talon pour horaires', 'service spécial demandé entre stations berri-uqam cartier', 'rappel interruption service cours service spécial fait navette entre stations berri-uqam cartier', \"service spécial fait navette entre stations h-bourassa berri-uqam autre alternative dans l'axe nordsud ligne st-denis st-hubert saint-laurent\"]\n",
      "\n",
      "Cluster 13:\n",
      "['pour vous déplacer entre stations jean-talon saint-michel vous pouvez utiliser lignes 99-villeray 93-jean-talon bélanger pour horaires', \"station honoré-beaugrand travaux voirie réouverture boucle d’autobus nord aujourd'hui\", 'ligne assure service entre station côte-vertu lionel-groulx itinéraire horaire', 'rappel station beaudry fermée raison d’une interv policière proximité station service toujours offert ligne verte mais aucun arrêt trains station beaudry pouvez prendre métro stations berri-uqam papineau situées proximité', 'réouverture station beaudry reprise service cette station']\n",
      "\n",
      "Cluster 14:\n",
      "['arrêt ligne entre longueuil berri-uqam personne autorisée rails reprise prévue vers', 'arrêt ligne entre angrignon l-groulx personne autorisée voie reprise prévue vers', 'arrêt ligne entre côte-vertu montncy personne autorisée voie reprise prévue vers', 'arrêt prolongé ligne entre sherbrooke montncy personne autorisée voie reprise prévue vers', 'arrêt prolongé ligne entre côte-vertu montncy personne autorisée voie reprise prévue vers']\n",
      "\n",
      "Cluster 15:\n",
      "['arrêt ligne entre longueuil berri-uqam panne train reprise prévue vers', 'arrêt prolongé ligne entre longueuil berri-uqam panne train reprise prévue vers', 'arrêt prolongé ligne entre longueuil berri-uqam panne train reprise prévue vers', 'arrêt ligne entre h-bourassa montncy panne train reprise prévue vers', 'arrêt ligne entre l-groulx mcgill panne train reprise prévue vers']\n",
      "\n",
      "Cluster 16:\n",
      "[\"férié aujourd'hui décembre c'est noël métro ouvert selon l'horaire dimanche service clientèle fermé comptoir objets perdus fermé\", \"férié aujourd'hui décembre c'est noël métro ouvert selon l'horaire dimanche service clientèle fermé comptoir objets perdus fermé\", \"férié aujourd'hui décembre c'est noël métro ouvert selon l'horaire dimanche service clientèle fermé comptoir objets perdus fermé\", \"férié aujourd'hui décembre c'est noël métro ouvert selon l'horaire dimanche service clientèle fermé comptoir objets perdus fermé\", \"férié aujourd'hui décembre c'est lendemain noël métro ouvert selon l'horaire dimanche service clientèle fermé comptoir objets perdus fermé\"]\n",
      "\n",
      "Cluster 17:\n",
      "[\"interruption cours service spécial place effectue navette entre stations snowdon parc l'emplacement arrêt indiqué plan quartier\", \"interruption cours service spécial effectue navette entre stations collège plamondon l'emplacement arrêt indiqué plan quartier\", \"interruption cours service spécial effectue navette entre stations montncy berri -uqam l'emplacement arrêt indiqué plan quartier\", \"interruption cours service spécial place pour effectuer navette entre stations honoré-beaugrand pie-ix l'emplacement arrêt indiqué plan quartier\", \"interruption cours service spécial place pour effectuer navette entre stations lionel-groulx collège consultez plan quartier pour trouver l'emplacement arrêt\"]\n",
      "\n",
      "Cluster 18:\n",
      "[\"service provisoire surface déployé entre berri-uqam honoré-beaugrand vous pouvez retrouver l'arrêt plans quartiers affichés dans l'ensemble stations\", \"service spécial déploie entre berri-uqam longueuil vous pouvez retrouver l'arrêt plans quartiers affichés dans l'ensemble stations\", \"interruption cours service spécial fait navette entre stations henri-bourassa beaubien vous pouvez retrouver l'arrêt plans quartiers affichés dans l'ensemble stations\", \"service spécial service spécial déploie entre berri-uqam honoré-beaugrand vous pouvez retrouver l'arrêt plans quartiers affichés dans l'ensemble stations stminfo stminfo plans réseaux plans réseaux plan réseau 2023 plan réseau 2023\", \"interruption cours service spécial fait navette entre stations côte-vertu lionel-groulx vous pouvez retrouver l'arrêt plans quartiers affichés dans l'ensemble stations\"]\n",
      "\n",
      "Cluster 19:\n",
      "['aujourd’hui métro montréal célèbre joignez-vous nous cette journée spéciale célébrations', \"interruption service raison d'un dégagement fumée équipes place travaillent rétablir service plus rapidement possible\", 'service rétabli ligne jaune', 'interruption service ligne jaune raison d’une intervention policière', 'reprise service ligne jaune']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Assuming you have a list of tweets in `tweets`\n",
    "\n",
    "# Convert the tweets into TF-IDF vectors\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df.tweet)\n",
    "\n",
    "# Apply K-means clustering\n",
    "num_clusters = 20  # You can adjust this parameter\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "kmeans.fit(tfidf_matrix)\n",
    "\n",
    "# Get the cluster labels for each tweet\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "# df_ = df.copy()\n",
    "# df_['cluster'] = 0\n",
    "# df_.cluster = cluster_labels\n",
    "# df_[df_.cluster==3].tweet.unique()\n",
    "\n",
    "# Print the tweets in each cluster\n",
    "for cluster_id in range(num_clusters):\n",
    "    print(f\"Cluster {cluster_id}:\")\n",
    "    cluster_tweets = [df.tweet.iloc[i] for i, label in enumerate(cluster_labels) if label == cluster_id]\n",
    "    print(cluster_tweets[:5])  # Print the first 5 tweets in the cluster\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1d438821",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000\n",
    "max_len = 50\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(df.tweet.values)\n",
    "sequences = tokenizer.texts_to_sequences(df.tweet.values)\n",
    "X_processed = pad_sequences(sequences, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "29e93f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,450</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m6,528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m6,450\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,746</span> (131.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m33,746\u001b[0m (131.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,746</span> (131.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m33,746\u001b[0m (131.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Encoder\n",
    "inputs = Input(shape=(max_len,))\n",
    "encoded = Dense(128, activation='relu')(inputs)\n",
    "encoded = Dense(64, activation='relu')(encoded)\n",
    "encoded = Dense(32, activation='relu')(encoded)\n",
    "\n",
    "# Decoder\n",
    "decoded = Dense(64, activation='relu')(encoded)\n",
    "decoded = Dense(128, activation='relu')(decoded)\n",
    "decoded = Dense(max_len, activation='sigmoid')(decoded)\n",
    "\n",
    "# Autoencoder Model\n",
    "autoencoder = Model(inputs, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "99a7feee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Argument `validation_split` is only supported for tensors or NumPy arrays.Found incompatible type in the input: [<class 'gensim.models.word2vec.Word2Vec'>, <class 'gensim.models.word2vec.Word2Vec'>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[149], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m autoencoder\u001b[38;5;241m.\u001b[39mfit(word2vec_model, word2vec_model, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/trainers/data_adapters/array_slicing.py:472\u001b[0m, in \u001b[0;36mtrain_validation_split\u001b[0;34m(arrays, validation_split)\u001b[0m\n\u001b[1;32m    470\u001b[0m unsplitable \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtype\u001b[39m(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m flat_arrays \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m can_slice_array(t)]\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unsplitable:\n\u001b[0;32m--> 472\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    473\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument `validation_split` is only supported \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    474\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor tensors or NumPy arrays.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound incompatible type in the input: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munsplitable\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    476\u001b[0m     )\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(t \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m flat_arrays):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arrays, arrays\n",
      "\u001b[0;31mValueError\u001b[0m: Argument `validation_split` is only supported for tensors or NumPy arrays.Found incompatible type in the input: [<class 'gensim.models.word2vec.Word2Vec'>, <class 'gensim.models.word2vec.Word2Vec'>]"
     ]
    }
   ],
   "source": [
    "autoencoder.fit(word2vec_model, word2vec_model, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8c718f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 32))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "21416889",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8180 - loss: 0.4995 - val_accuracy: 0.9882 - val_loss: 0.0568\n",
      "Epoch 2/10\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9913 - loss: 0.0406 - val_accuracy: 0.9908 - val_loss: 0.0307\n",
      "Epoch 3/10\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9959 - loss: 0.0164 - val_accuracy: 0.9908 - val_loss: 0.0301\n",
      "Epoch 4/10\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9921 - loss: 0.0229 - val_accuracy: 0.9934 - val_loss: 0.0206\n",
      "Epoch 5/10\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9989 - loss: 0.0092 - val_accuracy: 0.9961 - val_loss: 0.0182\n",
      "Epoch 6/10\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0026 - val_accuracy: 0.9948 - val_loss: 0.0232\n",
      "Epoch 7/10\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9987 - loss: 0.0046 - val_accuracy: 0.9961 - val_loss: 0.0201\n",
      "Epoch 8/10\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9993 - loss: 0.0024 - val_accuracy: 0.9961 - val_loss: 0.0189\n",
      "Epoch 9/10\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.1245e-04 - val_accuracy: 0.9921 - val_loss: 0.0261\n",
      "Epoch 10/10\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9982 - loss: 0.0069 - val_accuracy: 0.9961 - val_loss: 0.0174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x323e3c710>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, df.stop.values, test_size=0.2, random_state=42)\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b56b651e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9906 - loss: 0.0244\n",
      "Test accuracy: 0.987525999546051\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
